<!doctype html><html><head><meta charset=UTF-8><meta content="IE=edge" http-equiv=X-UA-Compatible><meta content="width=device-width,initial-scale=1.0" name=viewport><title>
        Webgraph from scratch (Draft)
    </title><link href=/corro.svg rel=icon type=image/png><link href=https://zom.wtf/fonts.css rel=stylesheet><link href=/path/to/folder/css/academicons.min.css rel=stylesheet><link href=https://zom.wtf/atom.xml rel=alternate title=zom.wtf type=application/atom+xml><link href=https://zom.wtf/theme/light.css rel=stylesheet><link href=https://zom.wtf/main.css media=screen rel=stylesheet><body><div class=content><header><div class=main><img id=title_icon src=/corro.svg><a href=https://zom.wtf>zom.wtf</a><div class=socials><a class=social href=https://twitter.com/zommiommy> <img alt=twitter src=/social_icons/twitter.svg> </a><a class=social href=https://github.com/zommiommy> <img alt=github src=/social_icons/github.svg> </a></div></div><nav><a href=/posts style=margin-left:.7em>/posts</a><a href=/about style=margin-left:.7em>/about</a><a href=/goodstuff style=margin-left:.7em>/good_stuff</a></nav></header><main><article><div class=title><div class=page-header>Webgraph from scratch (Draft)</div><div class=meta>Posted on <time>2023-04-19</time></div></div><h1>Table of Contents</h1><ul><li><a href=https://zom.wtf/posts/webgraph/#introduction>Introduction</a><li><a href=https://zom.wtf/posts/webgraph/#theoretical-preliminaries>Theoretical preliminaries</a> <ul><li><a href=https://zom.wtf/posts/webgraph/#information>Information</a></li><ul><li><a href=https://zom.wtf/posts/webgraph/#example>Example</a><li><a href=https://zom.wtf/posts/webgraph/#entropy>Entropy</a></ul><li><a href=https://zom.wtf/posts/webgraph/#instantaneous-code>Instantaneous code</a></li><ul><li><a href=https://zom.wtf/posts/webgraph/#intended-distribution>Intended distribution</a></ul><li><a href=https://zom.wtf/posts/webgraph/#universal-code>Universal code</a></ul><li><a href=https://zom.wtf/posts/webgraph/#codes>Codes</a> <ul><li><a href=https://zom.wtf/posts/webgraph/#fixed-length>Fixed length</a></li><ul><li><a href=https://zom.wtf/posts/webgraph/#example-for-n-4>Example for N = 4</a><li><a href=https://zom.wtf/posts/webgraph/#example-for-n-8>Example for N = 8</a></ul><li><a href=https://zom.wtf/posts/webgraph/#truncated-binary-encoding>Truncated Binary Encoding</a></li><ul><li><a href=https://zom.wtf/posts/webgraph/#example-for-n-6>Example for N = 6</a></ul><li><a href=https://zom.wtf/posts/webgraph/#unary>Unary</a><li><a href=https://zom.wtf/posts/webgraph/#elias-gamma>Elias-Gamma</a><li><a href=https://zom.wtf/posts/webgraph/#elias-delta>Elias-Delta</a><li><a href=https://zom.wtf/posts/webgraph/#golomb>Golomb</a><li><a href=https://zom.wtf/posts/webgraph/#vbytes>VBytes</a><li><a href=https://zom.wtf/posts/webgraph/#zeta>Zeta</a><li><a href=https://zom.wtf/posts/webgraph/#encoding-of-negative-numbers>Encoding of negative numbers</a><li><a href=https://zom.wtf/posts/webgraph/#codes-summary>Codes Summary</a></ul><li><a href=https://zom.wtf/posts/webgraph/#bvgraph>BVGraph</a> <ul><li><a href=https://zom.wtf/posts/webgraph/#example-1>Example</a><li><a href=https://zom.wtf/posts/webgraph/#compression-tradeoffs>Compression tradeoffs</a><li><a href=https://zom.wtf/posts/webgraph/#offsets-list>Offsets list</a><li><a href=https://zom.wtf/posts/webgraph/#benchmarks>Benchmarks</a><li><a href=https://zom.wtf/posts/webgraph/#how-to-choose-the-best-codes>How to choose the best codes?</a></ul><li><a href=https://zom.wtf/posts/webgraph/#computing-an-order>Computing an order</a> <ul><li><a href=https://zom.wtf/posts/webgraph/#bfs>BFS</a><li><a href=https://zom.wtf/posts/webgraph/#layered-labels-propagation>Layered Labels Propagation</a><li><a href=https://zom.wtf/posts/webgraph/#benchmarks-1>Benchmarks</a></ul><li><a href=https://zom.wtf/posts/webgraph/#references>References</a></ul><section class=body><h1 id=introduction>Introduction</h1><h1 id=theoretical-preliminaries>Theoretical preliminaries</h1><p>All bit sequences will be read from left to right, from top to bottom. For ease of reading I will be using the convention that <strong>all codes start from 0</strong> by adding a +1 where needed. This differs from the <strong>book definitions</strong> of the codes, but it's how you practically implement them.<h2 id=information>Information</h2><p>Information is define by the following axioms:<ul><li>The infomration \(I(p)\) of an event with probaility \(p\) is a monotone decreasing function of \(p\), i.e. \(p \le q \implies I(p) \ge I(q)\)<li>\(I(1) = 0\): The information content of a certain event is 0<li>Information is additive, i.e. the information of two independent events is the sum of the information of each event. \(I(p \cup q) = I(p) + I(q)\)</ul><p>The only function that satisfies these axioms is: \[I(p) = -\log_2 p\]<h4 id=example>Example</h4><p>A simple way to derive the information function for a discrete uniform distribution is the following:<p>Using \(n\) bits we can store \(2^n\) different values. We can invert this relationship as: a set of \(N = 2^n\) values with uniform probability has \(I(p) = \log_2 N = n\) bits of information.<p><em>We use uniform probability because we don't know anything about the data.</em><p>By definition, each value in the set has probability \(p = \frac{1}{N}\) so \(N = \frac{1}{p}\), so we can rewrite the information as: \[I(p) = -\log_2 \frac{1}{p} = -\log_2 p\]<p>which is exactly the definition of Information.<h3 id=entropy><a href=https://en.wikipedia.org/wiki/Entropy_(information_theory)>Entropy</a></h3><p><em>The entropy is the expected information.</em><p>Given a probability distribution \(p: S \to [0, 1]\) with support \(S\), the entropy of \(p\) in bits is defined as: \[\mathbb{H}(p) = -\sum_{s \in S} p(s) \log_2 p(s) = \mathbb{E}_p[-\log_2 p]\]<p>The entropy is a measure of the uncertainty of a random variable, it's maximized when all the values are equally likely and minimized when the distribution is a delta function i.e. one value has probability 1 while the other have probability 0.<p><strong>For our use cases, the entropy is the minimum number of bits needed to store a value extracted from a distribution.</strong><h2 id=instantaneous-code><a href=https://en.wikipedia.org/wiki/Prefix_code>Instantaneous code</a></h2><p>An instantaneous (binary) code (a.k.a. prefix-free code) for the set \(S\) is a function \(c : S \to {0, 1}^*\) such that, for all \(x, y \in S\), if \(c(x)\) is a prefix of \(c(y)\), then \(x = y\).<p><em>This implies that there is one unique way of decoding a given sequence</em><p><a href=https://en.wikipedia.org/wiki/Kraft%E2%80%93McMillan_inequality><strong>Kraft-McMillan</strong></a> tell us that there exists an instantaneous code with lengths \(|c(s)|\) (\(s \in S\)) if, and only if: \[\sum_{s \in S} 2^{-|c(s)|} \le 1\]<p>where \(l_s = |c(s)|\) is the length in bits of the code \(c(s)\) for value \(s \in S\).<p>A <strong>complete</strong> code is an instantaneous code where: \[\sum_{s \in S} 2^{-l_s} = 1\]<p><em>A complete code means that there are no unused codewords.</em><p>Furthermore, the expected length of \(c\) with respect to some probability distribution \(p: S \to [0, 1]\) with support \(S\) is:<p>\[\mathbb{E}_p[|c|] = \sum_{s \in S} p(s) |c(s)|\]<p>it follows that the <strong>optimal</strong> code \(c^*_p\) for a givend probability distribution \(P\) is the instantaneous code with minimum expected length.<p>If \(S\) is finite, Shannon's coding theorem tells us that the minimum expected length is the entropy of the distribution \(\mathbb{H}[p]\): \[\mathbb{E}_p[|c^*_p|] = \mathbb{H}(p)\]<p>moreover, the Huffman encoding is <strong>optimal</strong>.<h3 id=intended-distribution>Intended distribution</h3><p>Using the same equation for the expected lenght we can also compute the <strong>intended distribution</strong> i.e. the probability \(p\) that minimize the expected length \(\mathbb{E}_p[|c|]\) for a given code \(c\).<p>We can derive the intended distribution starting from: \[\mathbb{E}_p[|c^*_p|] = \mathbb{H}(p)\] by applying the respective defenitions: \[\sum_{s \ in S} p(s) |c(s)| = \sum_{s \in S} -p(s) \log_2 p(s)\] a way to make this holds is to impose that the inner terms of the sum must be equal: \[\forall s \in S \quad p(s) |c(s)| = -p(s) \log_2 p(s)\] we can factor out the common \(p(s)\) term (assuming it's not 0, in which case the equation still holds): \[\forall s \quad |c(s)| = -\log_2 p(s)\] and finally we can derive \(p(s)\): \[\forall s \quad p(s) = 2^{-|c(x)|}\]<p>Thus, the intended distribution for \(c\) is: \[p(x) = 2^{-|c(x)|}\]<p><em>Note that this is a proper distribution if and only if the code is complete, otherwise it won't sum to 1 and we would need some renormalization constant.</em><p>Therefore, to achieve best compression, <strong>we have to choose the code which intended distribution most closely match the data distribution</strong>.<h2 id=universal-code><a href=https://en.wikipedia.org/wiki/Universal_code_(data_compression)>Universal code</a></h2><h1 id=codes>Codes</h1><h3 id=fixed-length>Fixed length</h3><p>It's defined on a the set of values beween \(0\) and \(N\) (excluded) i.e. \(S = {0, 1, ..., N - 1}\), it reresents each element \(s \in S\) using \(\forall s \in S \quad |c(s)| = \lceil \log_2 N \rceil\) bits.<p>Thus, the fixed length code is optimal for uniform distributions of values in \(\left[0, N\right)\) if, and only if, \(N\) is a power of two.<h4 id=example-for-n-4>Example for N = 4</h4><table><thead><tr><th>Number<th>Code<tbody><tr><td>0<td>00<tr><td>1<td>01<tr><td>2<td>10<tr><td>3<td>11</table><p><em>Note that any other permutation of bits is also valid.</em><h4 id=example-for-n-8>Example for N = 8</h4><table><thead><tr><th>Number<th>Code<tbody><tr><td>0<td>000<tr><td>1<td>001<tr><td>2<td>010<tr><td>3<td>011<tr><td>4<td>100<tr><td>5<td>101<tr><td>6<td>110<tr><td>7<td>111</table><h3 id=truncated-binary-encoding><a href=https://en.wikipedia.org/wiki/Truncated_binary_encoding>Truncated Binary Encoding</a></h3><p>also known as minimal binary encoding, us used for uniform distributions where \(N\) is not a power of two.<p>The core idea is that we can write with \(\lfloor \log_2 N \rfloor\) bits the first \(2^{\lfloor \log_2 N \rfloor}\) values i.e. the up to the biggest power of two smaller than \(N\), and the remaining \(N - 2^{\lfloor \log_2 N \rfloor}\) values using \(\lceil \log_2 N \rceil\) bits.<h4 id=example-for-n-6>Example for N = 6</h4><table><thead><tr><th>Number<th>Code<tbody><tr><td>0<td>00<tr><td>1<td>01<tr><td>2<td>10<tr><td>3<td>11<tr><td>4<td>100<tr><td>5<td>101</table><p><strong>Note: this is not instantaneous! 2 is a prefix of 4 and 5! We will deal with this later.</strong><p>This is <strong>close to be optimal</strong>, as the expected code length is: \[\mathbb{E}[|c|] = \frac{2^{\lfloor \log_2 N \rfloor}}{N} \lfloor \log_2 N \rfloor \; + \; \left(1 - \frac{2^{\lfloor \log_2 N \rfloor}}{N} \right) \lceil \log_2 N \rceil \]<p>while the entropy is: \[\mathbb{H}[p] = \sum_{s \in S} -\frac{1}{N} \log_2 \frac{1}{N} = \log_2 N\]<p>If we define \(\alpha = \frac{2^{\lfloor \log_2 N \rfloor}}{N}\) we can notice that the expected length is the convex combination of \(\lfloor \log_2 N \rfloor\) and \(\lceil \log_2 N \rceil\):<p>\[\mathbb{E}[|c|] = \alpha \lfloor \log_2 N \rfloor \; + \; \left(1 - \alpha \right) \lceil \log_2 N \rceil \]<p>When \(N\) is a power of two this is equivalent to the fixed length and is optimal because: \[\mathbb{E}[|c|] = \lfloor \log_2 N \rfloor = \log_2 N = \lceil \log_2 N \rceil\]<p>Otherwise, by definition, a convex combination will only take cavlues between its extremes \(\lfloor \log_2 N \rfloor\) and \(\lceil \log_2 N \rceil\) so the truncated binary encoding is always smaller or equal than the fixed length.<h3 id=unary>Unary</h3><p>We can write any positive number \(s \in \mathbb{N} \) as a sequence of \(s\) zeros followed by a one, which act as a terminator.<p>This code has length \(s + 1\) therefore, its intended distribution is: \[p(x) = \left(\frac{1}{2}\right)^{x + 1}\]<p>Thus, it's optimal for geometric distributions with \(p = \frac{1}{2}\).<table><thead><tr><th>Number<th>Code<tbody><tr><td>0<td>1<tr><td>1<td>01<tr><td>2<td>001<tr><td>3<td>0001<tr><td>4<td>00001<tr><td>5<td>000001<tr><td>6<td>0000001<tr><td>7<td>00000001<tr><td>8<td>000000001</table><p>Most modern CPUs architectures, like x86_64 and Aarch64 (Arm), have instructions to compute the leading or traling zeros in a registers. Using these we can decode unary codes in 1 ns on average.<h3 id=elias-gamma><a href=https://en.wikipedia.org/wiki/Elias_gamma_coding#Further_reading>Elias-Gamma</a></h3><p>Unary + Fixed Length<table><thead><tr><th>Number<th>Code<tbody><tr><td>0<td>1<tr><td>1<td>01 0<tr><td>2<td>01 1<tr><td>3<td>001 00<tr><td>4<td>001 01<tr><td>5<td>001 10<tr><td>6<td>001 11<tr><td>7<td>0001 000<tr><td>8<td>0001 001</table><h3 id=elias-delta><a href=https://en.wikipedia.org/wiki/Elias_delta_coding>Elias-Delta</a></h3><p>What happens if we write the fixed length part of gamma, using another gamma?<p>MEME: Oh boy here I go recursing again MEME: I heard you like gamma, so I put another gamma inside your gamma<table><thead><tr><th>Number<th>Code<tbody><tr><td>0<td>1<tr><td>1<td>01 0 0<tr><td>2<td>01 1 1<tr><td>3<td>01 10 0<tr><td>4<td>01 10 1<tr><td>5<td>01 11 0<tr><td>6<td>01 11 1<tr><td>7<td>0001 00 000<tr><td>8<td>0001 00 001</table><h3 id=golomb>Golomb</h3><p>for a given b, write \(\lfloor \sfrac{s}{b} \rfloor \) in unary and \(s mod b\) using fixed lenght (or truncated encoding)<p>The length is \(|c(s)| = \left \lfloor \frac{s}{b} \right \rfloor + \lceil \log_2 b \rceil\) thus, its<p>For a Geometric distribution of ratio \(p\) we can compute the \(b\) so that the Golomb code is optimal: \[b = \left \lceil \frac{\log_2 (2 - p)}{-\log(1 - p)} \right \rceil\]<h3 id=vbytes>VBytes</h3><p>This code, in its variation LEB128 is really common as it's present in both DWARF format and Webassembly binary format.<p>Byte-aligned<p>write 7 bits and use the highest to set 0 if continue 1 if stop.<p>The faster variation is to have all the 0s at the start, so basically writing the number of bytes - 1 in unary at the start.<p>LEB128 is not complete and redundant as it has infinite encodings for each number as we can just add 0 padding on the top. Moreover, if a value uses 2 bytes we know that it must be bigger than 127, so we can subtract it to fit more values, and this can be done recursively.<h3 id=zeta><a href=https://vigna.di.unimi.it/ftp/papers/Codes.pdf>Zeta</a></h3><p>Unary + Truncated Encoding<pre class=language-python data-lang=python style=background:#0f1419;color:#bfbab0><code class=language-python data-lang=python><span style=color:#ff7733>from </span><span>math </span><span style=color:#ff7733>import </span><span>floor</span><span style=color:#bfbab0cc>, </span><span>ceil</span><span style=color:#bfbab0cc>, </span><span>log2
</span><span>
</span><span style=color:#ff7733>def </span><span style=color:#ffb454>write_zeta</span><span>(</span><span style=color:#f29718>value</span><span style=color:#bfbab0cc>, </span><span style=color:#f29718>k</span><span>):
</span><span>    value </span><span style=color:#f29668>+= </span><span style=color:#f29718>1
</span><span>    h </span><span style=color:#f29668>= </span><span style=font-style:italic;color:#39bae6>int</span><span>(</span><span style=color:#ffb454>floor</span><span>(</span><span style=color:#ffb454>log2</span><span>(value)) </span><span style=color:#f29668>/ </span><span>k)
</span><span>    u </span><span style=color:#f29668>= </span><span style=color:#f29718>2</span><span style=color:#f29668>**</span><span>((h </span><span style=color:#f29668>+ </span><span style=color:#f29718>1</span><span>) </span><span style=color:#f29668>* </span><span>k)
</span><span>    l </span><span style=color:#f29668>= </span><span style=color:#f29718>2</span><span style=color:#f29668>**</span><span>(h </span><span style=color:#f29668>* </span><span>k)
</span><span>
</span><span>    data  </span><span style=color:#f29668>= </span><span style=color:#ffb454>write_unary</span><span>(h)
</span><span>    data </span><span style=color:#f29668>+= </span><span style=color:#ffb454>write_minimal_binary</span><span>(value </span><span style=color:#f29668>- </span><span>l</span><span style=color:#bfbab0cc>, </span><span style=color:#f29718>max</span><span style=color:#f29668>=</span><span>u </span><span style=color:#f29668>- </span><span>l)
</span><span>    </span><span style=color:#ff7733>return </span><span>data
</span><span>
</span><span style=color:#ff7733>def </span><span style=color:#ffb454>len_zeta</span><span>(</span><span style=color:#f29718>value</span><span style=color:#bfbab0cc>, </span><span style=color:#f29718>k</span><span>):
</span><span>    value </span><span style=color:#f29668>+= </span><span style=color:#f29718>1
</span><span>    h </span><span style=color:#f29668>= </span><span style=font-style:italic;color:#39bae6>int</span><span>(</span><span style=color:#ffb454>floor</span><span>(</span><span style=color:#ffb454>log2</span><span>(value)) </span><span style=color:#f29668>/ </span><span>k)
</span><span>    u </span><span style=color:#f29668>= </span><span style=color:#f29718>2</span><span style=color:#f29668>**</span><span>((h </span><span style=color:#f29668>+ </span><span style=color:#f29718>1</span><span>) </span><span style=color:#f29668>* </span><span>k)
</span><span>    l </span><span style=color:#f29668>= </span><span style=color:#f29718>2</span><span style=color:#f29668>**</span><span>(h </span><span style=color:#f29668>* </span><span>k)
</span><span>    </span><span style=color:#ff7733>return </span><span style=color:#ffb454>len_unary</span><span>(h) </span><span style=color:#f29668>+ </span><span style=color:#ffb454>len_minimal_binary</span><span>(value </span><span style=color:#f29668>- </span><span>l</span><span style=color:#bfbab0cc>, </span><span style=color:#f29718>max</span><span style=color:#f29668>=</span><span>u </span><span style=color:#f29668>- </span><span>l)
</span><span>
</span><span>
</span><span style=color:#ff7733>def </span><span style=color:#ffb454>read_zeta</span><span>(</span><span style=color:#f29718>data</span><span style=color:#bfbab0cc>, </span><span style=color:#f29718>k</span><span>):
</span><span>    h, data </span><span style=color:#f29668>= </span><span style=color:#ffb454>read_unary</span><span>(data)
</span><span>    u </span><span style=color:#f29668>= </span><span style=color:#f29718>2</span><span style=color:#f29668>**</span><span>((h </span><span style=color:#f29668>+ </span><span style=color:#f29718>1</span><span>) </span><span style=color:#f29668>* </span><span>k)
</span><span>    l </span><span style=color:#f29668>= </span><span style=color:#f29718>2</span><span style=color:#f29668>**</span><span>(h </span><span style=color:#f29668>* </span><span>k)
</span><span>    r, data </span><span style=color:#f29668>= </span><span style=color:#ffb454>read_minimal_binary</span><span>(data</span><span style=color:#bfbab0cc>, </span><span style=color:#f29718>max</span><span style=color:#f29668>=</span><span>u </span><span style=color:#f29668>- </span><span>l)
</span><span>    </span><span style=color:#ff7733>return </span><span>l </span><span style=color:#f29668>+ </span><span>r </span><span style=color:#f29668>- </span><span style=color:#f29718>1</span><span>, data
</span></code></pre><h2 id=encoding-of-negative-numbers>Encoding of negative numbers</h2><p>All the discussed codes are defined over some subset of \(\mathbb{N}\), to encode over \(\mathbb{Z}\), we have to define a bijection \(\phi: \mathbb{Z} \to \mathbb{N}\).<p>If we can assume that the values form some kind of bell shape centered around zero, as we often do, it's best to map values with small absolute value to small integers, so it's natural to use the following bijection:<p>\[\phi(x) = \left\{\begin{matrix} -2 x & \text{if } x \le 0\\2 x - 1 & \text{otherwise}\end{matrix}\right.\] which has inverse: \[\phi^{-1}(x) = \left\{\begin{matrix} -x / 2 & \text{if } x = 0 \mod 2\\ (x + 1) / 2 & \text{otherwise}\end{matrix}\right.\]<p>this can be efficiently implemented as:<pre class=language-python data-lang=python style=background:#0f1419;color:#bfbab0><code class=language-python data-lang=python><span style=color:#ff7733>def </span><span style=color:#ffb454>nat2int</span><span>(</span><span style=color:#f29718>x</span><span>):
</span><span>    </span><span style=color:#ff7733>return </span><span>(x </span><span style=color:#f29668>>> </span><span style=color:#f29718>1</span><span>) </span><span style=color:#f29668>^ ~</span><span>((x </span><span style=color:#f29668>& </span><span style=color:#f29718>1</span><span>) </span><span style=color:#f29668>- </span><span style=color:#f29718>1</span><span>)
</span><span>
</span><span style=color:#ff7733>def </span><span style=color:#ffb454>int2nat</span><span>(</span><span style=color:#f29718>x</span><span>):
</span><span>    </span><span style=color:#ff7733>if </span><span>x </span><span style=color:#f29668>> </span><span style=color:#f29718>0</span><span>:
</span><span>        </span><span style=color:#ff7733>return </span><span>x </span><span style=color:#f29668><< </span><span style=color:#f29718>1
</span><span>    </span><span style=color:#ff7733>else</span><span>:
</span><span>        </span><span style=color:#ff7733>return </span><span>(x </span><span style=color:#f29668><< </span><span style=color:#f29718>1</span><span>) </span><span style=color:#f29668>| </span><span style=color:#f29718>1
</span></code></pre><p>which in x86_64 assembly should look like:<pre class=language-asm data-lang=asm style=background:#0f1419;color:#bfbab0><code class=language-asm data-lang=asm><span style=font-style:italic;color:#5c6773>; int2nat
</span><span style=font-style:italic;color:#5c6773>; rax = x
</span><span style=color:#ff7733>shl </span><span style=color:#f29718>rbx</span><span>, </span><span style=color:#f29718>rax</span><span>, </span><span style=color:#f29718>1</span><span style=font-style:italic;color:#5c6773> ; x << 1 = 2 * x
</span><span style=color:#ff7733>cmp </span><span style=color:#f29718>rax
</span><span style=color:#ff7733>adc </span><span style=color:#f29718>rax
</span><span>
</span><span style=font-style:italic;color:#5c6773>; nat2int
</span></code></pre><h2 id=codes-summary>Codes Summary</h2><table><thead><tr><th>Code<th>Distribution<tbody><tr><td>Fixed Length<td>Uniform were N is a power of two<tr><td>Truncated<td>Uniform<tr><td>Unary<td>Geometric with p = \\(\frac{1}{2}\\)<tr><td>Gamma<td><tr><td>Delta<td><tr><td>Zeta k = 3<td></table><h1 id=bvgraph>BVGraph</h1><p>BVGraph is a graph compression data-structure which exploits some common properties of real-world graphs. The basic idea is to use instantaneous codes to represent an adjacency list (a.k.a. CSR).<p>The BVGraph format has three core compression methods:<ul><li>A node can copy successors from a previous node<li>Intervals of nodes with consecutive ids are written as the tuple (start, len)<li>The remaning nodes are sorted and encoded as a sequence of gaps (differences between successive nodes).</ul><p>We can already notice that this compression depends from the node ids. Finding the optimal order is most likely NP Complete, so later in this post we will discuss some heuristic methods to find good orders.<h2 id=example-1>Example</h2><p><img alt src=/webgraph_graph.svg> Let's start by computing the neighbours of each node:<pre style=background:#0f1419;color:#bfbab0><code><span>0: 1,2
</span><span>1: 3
</span><span>2: 3
</span><span>3: 4,5,6
</span><span>4: 5,6,8
</span><span>5: 7
</span><span>6: 7
</span><span>7:
</span><span>8:
</span></code></pre><p>The bits properly identified<div><span class="tag tag_degree">011</span><span class="tag tag_reference_offset">1</span><span class="tag tag_nintervals">1</span><span class="tag tag_first_residual">1010</span><span class="tag tag_residual_gap">1010</span></div> Reading the codes we obtain: <div><span class="tag tag_degree">3</span><span class="tag tag_reference_offset">0</span><span class="tag tag_nintervals">0</span><span class="tag tag_first_residual">2</span><span class="tag tag_residual_gap">2</span></div> And after applying all the needed +1, -1 and nat -> signed converstions, we have: <div><span class="tag tag_degree">2</span><span class="tag tag_reference_offset">0</span><span class="tag tag_nintervals">0</span><span class="tag tag_first_residual">1</span><span class="tag tag_residual_gap">2</span></div><p>The default codes for BVGraph are:<table><thead><tr><th>Value<th>Code<tbody><tr><td class="tag tag_degree">Outdegree<td>Gamma<tr><td class="tag tag_reference_offset">ReferenceOffset<td>Unary<tr><td class="tag tag_blocks_count">BlockCount<td>Gamma<tr><td class="tag tag_blocks">Blocks<td>Gamma<tr><td class="tag tag_nintervals">IntervalCount<td>Gamma<tr><td class="tag tag_interval_start">IntervalStart<td>Gamma<tr><td class="tag tag_interval_len">IntervalLen<td>Gamma<tr><td class="tag tag_first_residual">FirstResidual<td>Zeta(3)<tr><td class="tag tag_residual_gap">ResidualGap<td>Zeta(3)</table><h2 id=compression-tradeoffs>Compression tradeoffs</h2><p>Compression windows, Reference chain length<h2 id=offsets-list>Offsets list</h2><p>To have have random-access on a BVGraph bitstream we need to store the bitoffsets at which each node codes start, analogously to the offsets list of a CSR matrix.<p>While this could just be a vector of integers, we can notice that the offsets are a monotone non decreasing sequence of positive integers, thus they can be represented using Elias-Fano!<p>For a BVGraph bitstream of length (l) of a graph with (|V|) nodes, Elias-Fano stores the offsets using at most \(|V| (2 + \lfloor \log2 \frac{l}{|V|} \rfloor)\) bits while having \(O(1)\) access (select).<p><a href=https://zom.wtf/posts/elias_fano_pt1><em>See my other post for more info on Elias-Fano</em></a><h2 id=benchmarks>Benchmarks</h2><h2 id=how-to-choose-the-best-codes>How to choose the best codes?</h2><p>Use universal codes, gamma is really fast so it's a good default choice. Otherwise we can "simulate" writing every piece with all the codes, this requires just a complete iteration over the nodes so it's feasible also on large graphs.<p>Webgraph-rs allows has an optimized binary utility for this.<p>In my practical application we don't save much memory, about 3 GB over a 126GB graph, but we found out that zeta3 and delta have similar compressions, so we use delta which is 4 times faster than zeta3.<h1 id=computing-an-order>Computing an order</h1><h2 id=bfs>BFS</h2><h2 id=layered-labels-propagation>Layered Labels Propagation</h2><h2 id=benchmarks-1>Benchmarks</h2><h1 id=references>References</h1><ul><li><a href=https://vigna.di.unimi.it/algoweb/WebGraph.pdf>https://vigna.di.unimi.it/algoweb/WebGraph.pdf</a><li><a href=https://webgraph.di.unimi.it/>https://webgraph.di.unimi.it/</a><li><a href=https://vigna.di.unimi.it/ftp/papers/Codes.pdf>https://vigna.di.unimi.it/ftp/papers/Codes.pdf</a><li><a href=https://www.ics.uci.edu/~djp3/classes/2008_01_01_INF141/Materials/p595-boldi.pdf>https://www.ics.uci.edu/~djp3/classes/2008_01_01_INF141/Materials/p595-boldi.pdf</a><li><a href=https://github.com/vigna/webgraph>https://github.com/vigna/webgraph</a><li><a href=https://github.com/vigna/webgraph-rs>https://github.com/vigna/webgraph-rs</a><li><a href=https://github.com/vigna/sux-rs>https://github.com/vigna/sux-rs</a><li><a href=https://boldi.di.unimi.it/Corsi/AlgorithmsForLargeGraphs/lesson1.pdf>https://boldi.di.unimi.it/Corsi/AlgorithmsForLargeGraphs/lesson1.pdf</a><li><a href=https://boldi.di.unimi.it/Corsi/AlgorithmsForLargeGraphs/lesson2.pdf>https://boldi.di.unimi.it/Corsi/AlgorithmsForLargeGraphs/lesson2.pdf</a><li><a href=https://boldi.di.unimi.it/Corsi/AlgorithmsForLargeGraphs/lesson3-1.pdf>https://boldi.di.unimi.it/Corsi/AlgorithmsForLargeGraphs/lesson3-1.pdf</a><li><a href=https://boldi.di.unimi.it/Corsi/AlgorithmsForLargeGraphs/lesson3-2.pdf>https://boldi.di.unimi.it/Corsi/AlgorithmsForLargeGraphs/lesson3-2.pdf</a><li><a href=https://boldi.di.unimi.it/Corsi/AlgorithmsForLargeGraphs/lesson4-1.pdf>https://boldi.di.unimi.it/Corsi/AlgorithmsForLargeGraphs/lesson4-1.pdf</a><li><a href=https://boldi.di.unimi.it/Corsi/AlgorithmsForLargeGraphs/lesson4-2.pdf>https://boldi.di.unimi.it/Corsi/AlgorithmsForLargeGraphs/lesson4-2.pdf</a></ul></section></article></main></div><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script async id=MathJax-script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>